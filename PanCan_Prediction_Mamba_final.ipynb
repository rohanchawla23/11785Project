{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGAsE46JOYvK",
        "outputId": "864f5048-1089-4a5e-ef46-17e06ea95149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LotKYpQBwPc4"
      },
      "outputs": [],
      "source": [
        "# Load JSON data from file\n",
        "# TODO: edit path here\n",
        "dataset_path = '/content/drive/MyDrive/S24-11-785/mimic_data.json'\n",
        "\n",
        "\n",
        "with open(dataset_path, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "    # Inspect the first few entries to visualize dataset structure\n",
        "    # Note: each patient ID has a (widely) varying number of associated keys\n",
        "    for patient_id in list(data.keys())[:15]:\n",
        "        print(patient_id, data[patient_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6mR1UohYeR-"
      },
      "outputs": [],
      "source": [
        "# Load medical code dictionaries\n",
        "# This is meant to help ensure test and training data\n",
        "# have the same labels for ICD codes.\n",
        "\n",
        "# TODO: edit paths here\n",
        "codes1path = '/content/drive/MyDrive/S24-11-785/icd8_disease_descriptions.tsv'\n",
        "codes2path = '/content/drive/MyDrive/S24-11-785/icd9_disease_descriptions.tsv'\n",
        "codes3path = '/content/drive/MyDrive/S24-11-785/icd10_disease_descriptions.tsv'\n",
        "\n",
        "codes_dict = {}\n",
        "\n",
        "i = 0\n",
        "\n",
        "PAD_TOKEN = i\n",
        "codes_dict['<pad>'] = i\n",
        "i += 1\n",
        "\n",
        "CLS_TOKEN = i\n",
        "codes_dict['<cls>'] = i\n",
        "i += 1\n",
        "\n",
        "with open(codes1path, 'r') as f:\n",
        "  for line in f.readlines():\n",
        "    line = line.strip().split('\\t')\n",
        "    if line[0] not in codes_dict:\n",
        "      codes_dict[line[0]] = i\n",
        "      i += 1\n",
        "\n",
        "with open(codes2path, 'r') as f:\n",
        "  start = True\n",
        "  for line in f.readlines():\n",
        "    if start:\n",
        "      start = False\n",
        "      continue\n",
        "    line = line.strip().split('\\t')\n",
        "    if line[0] not in codes_dict:\n",
        "      codes_dict[line[0]] = i\n",
        "      i += 1\n",
        "\n",
        "with open(codes3path, 'r') as f:\n",
        "  start = True\n",
        "  for line in f.readlines():\n",
        "    if start:\n",
        "      start = False\n",
        "      continue\n",
        "    line = line.strip().split('\\t')\n",
        "    if line[0] not in codes_dict:\n",
        "      codes_dict[line[0]] = i\n",
        "      i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP3ZR78JPzwz"
      },
      "outputs": [],
      "source": [
        "# Dataset Class definition\n",
        "# NOTE:  we include admdates and bdates for each patient, but we ddin't use this information in our\n",
        "# final model. Basically, admdate for each visit is the number of days between that visit date and the \n",
        "# patient's final (pre-cancer diagnosis) visit. The bdate for each visit is their age (in days) at a visit date\n",
        "# The baseline modle used this information to calculate positional encodings for the visits. We didn't need \n",
        "# positional encodings for our data, but it might be possible in a future extension to incorporate these\n",
        "# dates as features.\n",
        "\n",
        "\n",
        "class HealthRecordDataset(Dataset):\n",
        "    PANC_CANCER_CODES = {\n",
        "        'C25', 'C253', 'C252', 'C259', 'C250', 'C251', 'C258',\n",
        "        'C254', 'C257', '157', '1573', '1570', '1579', '1578',\n",
        "        '1571', '1574', '1572'\n",
        "    } # these are the codes that CancerRiskNet associated with a 'positive' diagnosis\n",
        "\n",
        "    def __init__(self, data, codes_dict, exclude_past6 = False):\n",
        "        self.data = []\n",
        "        self.bdates = []\n",
        "        self.admdates = []\n",
        "        self.labels = []\n",
        "\n",
        "        TWO_MONTHS = 30 * 2\n",
        "        SIX_MONTHS = 30 * 6\n",
        "        TWELVE_MONTHS = 30 * 12\n",
        "        TWO_YEARS = 30 * 24\n",
        "        THIRTYSIX_MONTHS = 30 * 36\n",
        "        SIXTY_MONTHS = 30 * 60\n",
        "\n",
        "        # Convert records to integer sequences & assign labels\n",
        "        for _, record in data.items():\n",
        "            evnts = []\n",
        "            features = []\n",
        "            lbls = [0] * 5\n",
        "\n",
        "            canc_date = datetime.fromisoformat(record['end_of_data'])\n",
        "            cancer = False\n",
        "\n",
        "            for event in record['events']:\n",
        "              for code in event['codes'].split(\",\"):\n",
        "                # update dictionary if you encounter a new code\n",
        "                if code not in codes_dict:\n",
        "                  codes_dict[code] = len(codes_dict)\n",
        "\n",
        "                # if patient has cancer, don't add this visit to your list of visits\n",
        "                if code in self.PANC_CANCER_CODES:\n",
        "                  canc_date = datetime.fromisoformat(event['admdate'])\n",
        "                  cancer = True\n",
        "                  break\n",
        "\n",
        "                evnts.append(event)\n",
        "              # if patient has cancer, stop considering future events\n",
        "              if cancer:\n",
        "                break\n",
        "            \n",
        "            # this ignores patients with no prior history to cancer\n",
        "            if len(evnts) == 0:\n",
        "              continue\n",
        "            last_feat_date = datetime.fromisoformat(evnts[-1]['admdate'])\n",
        "\n",
        "            # we didn't actually use this code, but the authors in the baseline did\n",
        "            # basically, they excluded all visits 6 months prior to the cancer diagnosis\n",
        "            # in case they were highly related to the cancer diagnosis. The issue is that\n",
        "            # many of the patient histories in our data were too short to do this, \n",
        "            # since excluding the prior 6 months, 3 months or even 2 months to the \n",
        "            # cancer diagnosis resulted in some patients with no history at all\n",
        "            if exclude_past6:\n",
        "              for event in evnts:\n",
        "                if abs(canc_date - datetime.fromisoformat(event['admdate'])).days > SIX_MONTHS:\n",
        "                  last_feat_date = datetime.fromisoformat(event['admdate'])\n",
        "                  for code in event['codes'].split(\",\"):\n",
        "                    features.append(codes_dict[code])\n",
        "            else:\n",
        "              for event in evnts:\n",
        "                last_feat_date = datetime.fromisoformat(event['admdate'])\n",
        "                for code in event['codes'].split(\",\"):\n",
        "                    features.append(codes_dict[code])\n",
        "\n",
        "            features.append(CLS_TOKEN)\n",
        "\n",
        "            # create labels\n",
        "            if cancer:\n",
        "              if abs(canc_date - last_feat_date).days < TWO_MONTHS:\n",
        "                lbls[0] = 1\n",
        "              if abs(canc_date - last_feat_date).days < SIX_MONTHS:\n",
        "                lbls[1] = 1\n",
        "              if abs(canc_date - last_feat_date).days < TWELVE_MONTHS:\n",
        "                lbls[2] = 1\n",
        "              if abs(canc_date - last_feat_date).days < THIRTYSIX_MONTHS:\n",
        "                lbls[3] = 1\n",
        "              if abs(canc_date - last_feat_date).days < SIXTY_MONTHS:\n",
        "                lbls[4] = 1\n",
        "\n",
        "            \n",
        "            admdates = [datetime.fromisoformat(event['admdate']) for event in record['events']]\n",
        "            bday = datetime.fromisoformat(record['birthdate'])\n",
        "\n",
        "            ref = admdates[-1]\n",
        "            adm_deltas = np.array([abs((ref - date).days) for date in admdates])\n",
        "            ref = bday\n",
        "            bday_deltas = np.array([abs((ref - date).days) for date in admdates])\n",
        "\n",
        "            self.data.append(features)\n",
        "            self.admdates.append(adm_deltas)\n",
        "            self.labels.append(lbls)\n",
        "            self.bdates.append(bday_deltas)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        out1 = torch.tensor(self.data[idx])\n",
        "        out2 = torch.tensor(self.admdates[idx])\n",
        "        out3 = torch.tensor(self.bdates[idx])\n",
        "        out4 = torch.tensor(self.labels[idx])\n",
        "        return out1, out2, out3, out4\n",
        "\n",
        "# Collate function for DataLoader zero-padding\n",
        "def collate_fn(batch):\n",
        "    features, admdates, bdates, labels = zip(*batch)\n",
        "    features_padded = pad_sequence(features, batch_first=True, padding_value=PAD_TOKEN)\n",
        "\n",
        "    admdates_padded = pad_sequence(admdates, batch_first=True, padding_value=PAD_TOKEN)\n",
        "    bdates_padded = pad_sequence(bdates, batch_first=True, padding_value=PAD_TOKEN)\n",
        "\n",
        "    ftr_lengths = [len(i) for i in features]\n",
        "    return features_padded, torch.stack(labels), admdates_padded, bdates_padded, torch.tensor(ftr_lengths)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUe4jBPJRGjT"
      },
      "outputs": [],
      "source": [
        "# Creating datasets and DataLoaders\n",
        "dataset = HealthRecordDataset(data, codes_dict)\n",
        "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGX21n-Qhl51",
        "outputId": "e421f5c0-b7cc-41a8-a01d-e7e0337375c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_pad shape:\t\ttorch.Size([32, 167])\n",
            "x_len shape:\t\ttorch.Size([32])\n",
            "\n",
            "y shape:\ttorch.Size([32, 5])\n",
            "torch.Size([32, 211])\n",
            "torch.Size([32, 211])\n"
          ]
        }
      ],
      "source": [
        "for batch in train_loader:\n",
        "    x_pad, y, admdates, bdates, x_len, = batch\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"x_pad shape:\\t\\t{x_pad.shape}\")\n",
        "    print(f\"x_len shape:\\t\\t{x_len.shape}\\n\")\n",
        "\n",
        "    print(f\"y shape:\\t{y.shape}\")\n",
        "    print(admdates.shape)\n",
        "    print(bdates.shape)\n",
        "    # print(y_shifted_pad)\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH7RqGWpxXcG"
      },
      "outputs": [],
      "source": [
        "\"\"\"Simple, minimal implementation of Mamba in one file of PyTorch.\n",
        "\n",
        "Suggest reading the following before/while reading the code:\n",
        "    [1] Mamba: Linear-Time Sequence Modeling with Selective State Spaces (Albert Gu and Tri Dao)\n",
        "        https://arxiv.org/abs/2312.00752\n",
        "    [2] The Annotated S4 (Sasha Rush and Sidd Karamcheti)\n",
        "        https://srush.github.io/annotated-s4\n",
        "\n",
        "Glossary:\n",
        "    b: batch size                       (`B` in Mamba paper [1] Algorithm 2)\n",
        "    l: sequence length                  (`L` in [1] Algorithm 2)\n",
        "    d or d_model: hidden dim\n",
        "    n or d_state: latent state dim      (`N` in [1] Algorithm 2)\n",
        "    expand: expansion factor            (`E` in [1] Section 3.4)\n",
        "    d_in or d_inner: d * expand         (`D` in [1] Algorithm 2)\n",
        "    A, B, C, D: state space parameters  (See any state space representation formula)\n",
        "                                        (B, C are input-dependent (aka selective, a key innovation in Mamba); A, D are not)\n",
        "    Δ or delta: input-dependent step size\n",
        "    dt_rank: rank of Δ                  (See [1] Section 3.6 \"Parameterization of ∆\")\n",
        "\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "import math\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dataclasses import dataclass\n",
        "from einops import rearrange, repeat, einsum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFuTGNlewXaB"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ModelArgs:\n",
        "    d_model: int\n",
        "    n_layer: int\n",
        "    vocab_size: int\n",
        "    d_state: int = 16\n",
        "    expand: int = 2\n",
        "    dt_rank: Union[int, str] = 'auto'\n",
        "    d_conv: int = 4\n",
        "    pad_vocab_size_multiple: int = 8\n",
        "    conv_bias: bool = True\n",
        "    bias: bool = False\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.d_inner = int(self.expand * self.d_model)\n",
        "\n",
        "        if self.dt_rank == 'auto':\n",
        "            self.dt_rank = math.ceil(self.d_model / 16)\n",
        "\n",
        "        if self.vocab_size % self.pad_vocab_size_multiple != 0:\n",
        "            self.vocab_size += (self.pad_vocab_size_multiple\n",
        "                                - self.vocab_size % self.pad_vocab_size_multiple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy-2RnoCxRf4"
      },
      "outputs": [],
      "source": [
        "class Mamba(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.embedding = nn.Embedding(args.vocab_size, args.d_model)\n",
        "        self.layers = nn.ModuleList([ResidualBlock(args) for _ in range(args.n_layer)])\n",
        "        self.norm_f = RMSNorm(args.d_model)\n",
        "\n",
        "    def forward(self, input_ids, adm_deltas, bdeltas):\n",
        "        x = self.embedding(input_ids)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = self.norm_f(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def from_pretrained(pretrained_model_name: str):\n",
        "        \"\"\"Load pretrained weights from HuggingFace into model.\n",
        "\n",
        "        Args:\n",
        "            pretrained_model_name: One of\n",
        "                * 'state-spaces/mamba-2.8b-slimpj'\n",
        "                * 'state-spaces/mamba-2.8b'\n",
        "                * 'state-spaces/mamba-1.4b'\n",
        "                * 'state-spaces/mamba-790m'\n",
        "                * 'state-spaces/mamba-370m'\n",
        "                * 'state-spaces/mamba-130m'\n",
        "\n",
        "        Returns:\n",
        "            model: Mamba model with weights loaded\n",
        "\n",
        "        \"\"\"\n",
        "        from transformers.utils import WEIGHTS_NAME, CONFIG_NAME\n",
        "        from transformers.utils.hub import cached_file\n",
        "\n",
        "        def load_config_hf(model_name):\n",
        "            resolved_archive_file = cached_file(model_name, CONFIG_NAME,\n",
        "                                                _raise_exceptions_for_missing_entries=False)\n",
        "            return json.load(open(resolved_archive_file))\n",
        "\n",
        "\n",
        "        def load_state_dict_hf(model_name, device=None, dtype=None):\n",
        "            resolved_archive_file = cached_file(model_name, WEIGHTS_NAME,\n",
        "                                                _raise_exceptions_for_missing_entries=False)\n",
        "            return torch.load(resolved_archive_file, weights_only=True, map_location='cpu', mmap=True)\n",
        "\n",
        "        config_data = load_config_hf(pretrained_model_name)\n",
        "        args = ModelArgs(\n",
        "            d_model=config_data['d_model'],\n",
        "            n_layer=config_data['n_layer'],\n",
        "            vocab_size=config_data['vocab_size']\n",
        "        )\n",
        "        model = Mamba(args)\n",
        "\n",
        "        state_dict = load_state_dict_hf(pretrained_model_name)\n",
        "        new_state_dict = {}\n",
        "        for key in state_dict:\n",
        "            new_key = key.replace('backbone.', '')\n",
        "            new_state_dict[new_key] = state_dict[key]\n",
        "        model.load_state_dict(new_state_dict)\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQpnhP0KxNNf"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, args: ModelArgs):\n",
        "        \"\"\"Simple block wrapping Mamba block with normalization and residual connection.\"\"\"\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.mixer = MambaBlock(args)\n",
        "        self.norm = RMSNorm(args.d_model)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: shape (b, l, d)    (See Glossary at top for definitions of b, l, d_in, n...)\n",
        "\n",
        "        Returns:\n",
        "            output: shape (b, l, d)\n",
        "\n",
        "        Official Implementation:\n",
        "            Block.forward(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L297\n",
        "\n",
        "            Note: the official repo chains residual blocks that look like\n",
        "                [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> [Add -> Norm -> Mamba] -> ...\n",
        "            where the first Add is a no-op. This is purely for performance reasons as this\n",
        "            allows them to fuse the Add->Norm.\n",
        "\n",
        "            We instead implement our blocks as the more familiar, simpler, and numerically equivalent\n",
        "                [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> [Norm -> Mamba -> Add] -> ....\n",
        "\n",
        "        \"\"\"\n",
        "        output = self.mixer(self.norm(x)) + x\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hsp-g1pSxKT1"
      },
      "outputs": [],
      "source": [
        "class MambaBlock(nn.Module):\n",
        "    def __init__(self, args: ModelArgs):\n",
        "        \"\"\"A single Mamba block, as described in Figure 3 in Section 3.4 in the Mamba paper [1].\"\"\"\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "\n",
        "        self.in_proj = nn.Linear(args.d_model, args.d_inner * 2, bias=args.bias)\n",
        "\n",
        "        self.conv1d = nn.Conv1d(\n",
        "            in_channels=args.d_inner,\n",
        "            out_channels=args.d_inner,\n",
        "            bias=args.conv_bias,\n",
        "            kernel_size=args.d_conv,\n",
        "            groups=args.d_inner,\n",
        "            padding=args.d_conv - 1,\n",
        "        )\n",
        "\n",
        "        # x_proj takes in `x` and outputs the input-specific Δ, B, C\n",
        "        self.x_proj = nn.Linear(args.d_inner, args.dt_rank + args.d_state * 2, bias=False)\n",
        "\n",
        "        # dt_proj projects Δ from dt_rank to d_in\n",
        "        self.dt_proj = nn.Linear(args.dt_rank, args.d_inner, bias=True)\n",
        "\n",
        "        A = repeat(torch.arange(1, args.d_state + 1), 'n -> d n', d=args.d_inner)\n",
        "        self.A_log = nn.Parameter(torch.log(A))\n",
        "        self.D = nn.Parameter(torch.ones(args.d_inner))\n",
        "        self.out_proj = nn.Linear(args.d_inner, args.d_model, bias=args.bias)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Mamba block forward. This looks the same as Figure 3 in Section 3.4 in the Mamba paper [1].\n",
        "\n",
        "        Args:\n",
        "            x: shape (b, l, d)    (See Glossary at top for definitions of b, l, d_in, n...)\n",
        "\n",
        "        Returns:\n",
        "            output: shape (b, l, d)\n",
        "\n",
        "        Official Implementation:\n",
        "            class Mamba, https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L119\n",
        "            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n",
        "\n",
        "        \"\"\"\n",
        "        (b, l, d) = x.shape\n",
        "\n",
        "        x_and_res = self.in_proj(x)  # shape (b, l, 2 * d_in)\n",
        "        (x, res) = x_and_res.split(split_size=[self.args.d_inner, self.args.d_inner], dim=-1)\n",
        "\n",
        "        x = rearrange(x, 'b l d_in -> b d_in l')\n",
        "        x = self.conv1d(x)[:, :, :l]\n",
        "        x = rearrange(x, 'b d_in l -> b l d_in')\n",
        "\n",
        "        x = F.silu(x)\n",
        "\n",
        "        y = self.ssm(x)\n",
        "\n",
        "        y = y * F.silu(res)\n",
        "\n",
        "        output = self.out_proj(y)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def ssm(self, x):\n",
        "        \"\"\"Runs the SSM. See:\n",
        "            - Algorithm 2 in Section 3.2 in the Mamba paper [1]\n",
        "            - run_SSM(A, B, C, u) in The Annotated S4 [2]\n",
        "\n",
        "        Args:\n",
        "            x: shape (b, l, d_in)    (See Glossary at top for definitions of b, l, d_in, n...)\n",
        "\n",
        "        Returns:\n",
        "            output: shape (b, l, d_in)\n",
        "\n",
        "        Official Implementation:\n",
        "            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n",
        "\n",
        "        \"\"\"\n",
        "        (d_in, n) = self.A_log.shape\n",
        "\n",
        "        # Compute ∆ A B C D, the state space parameters.\n",
        "        #     A, D are input independent (see Mamba paper [1] Section 3.5.2 \"Interpretation of A\" for why A isn't selective)\n",
        "        #     ∆, B, C are input-dependent (this is a key difference between Mamba and the linear time invariant S4,\n",
        "        #                                  and is why Mamba is called **selective** state spaces)\n",
        "\n",
        "        A = -torch.exp(self.A_log.float())  # shape (d_in, n)\n",
        "        D = self.D.float()\n",
        "\n",
        "        x_dbl = self.x_proj(x)  # (b, l, dt_rank + 2*n)\n",
        "\n",
        "        (delta, B, C) = x_dbl.split(split_size=[self.args.dt_rank, n, n], dim=-1)  # delta: (b, l, dt_rank). B, C: (b, l, n)\n",
        "        delta = F.softplus(self.dt_proj(delta))  # (b, l, d_in)\n",
        "\n",
        "        y = self.selective_scan(x, delta, A, B, C, D)  # This is similar to run_SSM(A, B, C, u) in The Annotated S4 [2]\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "    def selective_scan(self, u, delta, A, B, C, D):\n",
        "        \"\"\"Does selective scan algorithm. See:\n",
        "            - Section 2 State Space Models in the Mamba paper [1]\n",
        "            - Algorithm 2 in Section 3.2 in the Mamba paper [1]\n",
        "            - run_SSM(A, B, C, u) in The Annotated S4 [2]\n",
        "\n",
        "        This is the classic discrete state space formula:\n",
        "            x(t + 1) = Ax(t) + Bu(t)\n",
        "            y(t)     = Cx(t) + Du(t)\n",
        "        except B and C (and the step size delta, which is used for discretization) are dependent on the input x(t).\n",
        "\n",
        "        Args:\n",
        "            u: shape (b, l, d_in)    (See Glossary at top for definitions of b, l, d_in, n...)\n",
        "            delta: shape (b, l, d_in)\n",
        "            A: shape (d_in, n)\n",
        "            B: shape (b, l, n)\n",
        "            C: shape (b, l, n)\n",
        "            D: shape (d_in,)\n",
        "\n",
        "        Returns:\n",
        "            output: shape (b, l, d_in)\n",
        "\n",
        "        Official Implementation:\n",
        "            selective_scan_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L86\n",
        "            Note: I refactored some parts out of `selective_scan_ref` out, so the functionality doesn't match exactly.\n",
        "\n",
        "        \"\"\"\n",
        "        (b, l, d_in) = u.shape\n",
        "        n = A.shape[1]\n",
        "\n",
        "        # Discretize continuous parameters (A, B)\n",
        "        # - A is discretized using zero-order hold (ZOH) discretization (see Section 2 Equation 4 in the Mamba paper [1])\n",
        "        # - B is discretized using a simplified Euler discretization instead of ZOH. From a discussion with authors:\n",
        "        #   \"A is the more important term and the performance doesn't change much with the simplification on B\"\n",
        "        deltaA = torch.exp(einsum(delta, A, 'b l d_in, d_in n -> b l d_in n'))\n",
        "        deltaB_u = einsum(delta, B, u, 'b l d_in, b l n, b l d_in -> b l d_in n')\n",
        "\n",
        "        # Perform selective scan (see scan_SSM() in The Annotated S4 [2])\n",
        "        # Note that the below is sequential, while the official implementation does a much faster parallel scan that\n",
        "        # is additionally hardware-aware (like FlashAttention).\n",
        "        x = torch.zeros((b, d_in, n), device=deltaA.device)\n",
        "        ys = []\n",
        "        for i in range(l):\n",
        "            x = deltaA[:, i] * x + deltaB_u[:, i]\n",
        "            y = einsum(x, C[:, i, :], 'b d_in n, b n -> b d_in')\n",
        "            ys.append(y)\n",
        "        y = torch.stack(ys, dim=1)  # shape (b, l, d_in)\n",
        "\n",
        "        y = y + u * D\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcRQ-V0lxGdk"
      },
      "outputs": [],
      "source": [
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model: int,\n",
        "                 eps: float = 1e-5):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(d_model))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps) * self.weight\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txLJhsADBJnk"
      },
      "source": [
        "# Define our Pancreatic Cancer Model using Mamba modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prG0NwG3JgLS"
      },
      "outputs": [],
      "source": [
        "class PancCancerModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, args, pad_token=PAD_TOKEN, dropout=0.1):\n",
        "\n",
        "        super(PancCancerModel, self).__init__()\n",
        "\n",
        "        self.mamba = Mamba(args)\n",
        "        self.final = torch.nn.Linear(args.d_model, 5)\n",
        "\n",
        "    def forward(self, padded_input, input_lengths, adm_deltas, bdeltas):\n",
        "\n",
        "        out = self.mamba(padded_input, adm_deltas, bdeltas)\n",
        "        out = self.final(out[:,-1,:])\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pNox_N_1VwY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ModelArgs:\n",
        "    def __init__(self, d_model, n_layer, vocab_size, d_inner, d_conv, expand, bias=True, conv_bias=True, dt_rank=2, d_state=16):\n",
        "        self.d_model = d_model\n",
        "        self.n_layer = n_layer\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_inner = d_inner\n",
        "        self.d_conv = d_conv\n",
        "        self.expand = expand\n",
        "        self.bias = bias\n",
        "        self.conv_bias = conv_bias\n",
        "        self.dt_rank = dt_rank\n",
        "        self.d_state = d_state\n",
        "\n",
        "# Define model arguments\n",
        "args = ModelArgs(\n",
        "    d_model=16,    # Model dimension\n",
        "    n_layer=4,     # Number of layers\n",
        "    vocab_size=len(codes_dict),  # Vocabulary size\n",
        "    d_inner=128,    # Dimension of inner layers\n",
        "    d_conv=4,      # Convolution kernel size\n",
        "    expand=2       # Expansion factor\n",
        ")\n",
        "\n",
        "# Initialize the model\n",
        "model = PancCancerModel(args).to(\"cuda\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjT66x3M4YhB",
        "outputId": "a04dd97d-f1e4-4d64-b556-233639ae0c52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PancCancerModel(\n",
            "  (mamba): Mamba(\n",
            "    (embedding): Embedding(31565, 16)\n",
            "    (layers): ModuleList(\n",
            "      (0-3): 4 x ResidualBlock(\n",
            "        (mixer): MambaBlock(\n",
            "          (in_proj): Linear(in_features=16, out_features=256, bias=True)\n",
            "          (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
            "          (x_proj): Linear(in_features=128, out_features=34, bias=False)\n",
            "          (dt_proj): Linear(in_features=2, out_features=128, bias=True)\n",
            "          (out_proj): Linear(in_features=128, out_features=16, bias=True)\n",
            "        )\n",
            "        (norm): RMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm_f): RMSNorm()\n",
            "  )\n",
            "  (final): Linear(in_features=16, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDSYCK9L1axh",
        "outputId": "3c79d562-3590-4195-fc7a-e92d694f1a69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test passed successfully with output shape: torch.Size([2, 5])\n"
          ]
        }
      ],
      "source": [
        "# Test input setup\n",
        "batch, length, vocab_size, out_size = 2, 64, 5000, 5\n",
        "input_ids = torch.randint(0, vocab_size, (batch, length)).to(\"cuda\")  # Simulate input IDs\n",
        "adm_deltas = torch.randn(batch, length).to(\"cuda\")  # Simulated admission deltas\n",
        "bdeltas = torch.randn(batch, length).to(\"cuda\")     # Simulated birth date deltas\n",
        "\n",
        "# Forward pass\n",
        "y = model(input_ids, input_ids, adm_deltas, bdeltas)\n",
        "\n",
        "# Assert output shape\n",
        "assert y.shape == (batch, out_size), \"Output shape is incorrect\"\n",
        "\n",
        "print(\"Test passed successfully with output shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ0SzivWggFS",
        "outputId": "8d5bf57d-9e83-479b-c12f-b45e1011ebc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test passed successfully with output shape: torch.Size([32, 5])\n"
          ]
        }
      ],
      "source": [
        "# Test model on Panc Cancer Data\n",
        "\n",
        "x_pad, labels, admdates, bdates, x_len = x_pad.to(\"cuda\"), y.to(\"cuda\"), admdates.to(\"cuda\"), bdates.to(\"cuda\"), x_len.to(\"cuda\")\n",
        "\n",
        "y = model(x_pad, x_len, admdates, bdates)\n",
        "\n",
        "print(\"Test passed successfully with output shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZvUltoX7G08"
      },
      "source": [
        "# Full Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vnJBSgH7Ie1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset = HealthRecordDataset(data, codes_dict)\n",
        "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(test_data, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Initialize the model\n",
        "model = PancCancerModel(args).to(\"cuda\")\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Store metrics for plotting\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_aurocs = []\n",
        "val_aurocs = []\n",
        "\n",
        "# Training and Validation Loop\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    train_preds = []\n",
        "    train_labels = []\n",
        "\n",
        "    for x_pad, labels, adm_d, bd, x_len in train_loader:\n",
        "        x_pad, labels, adm_d, bd, x_len = x_pad.to(\"cuda\"), labels.to(\"cuda\"), adm_d.to(\"cuda\"), bd.to(\"cuda\"), x_len.to(\"cuda\")\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_pad, x_len, adm_d, bd)\n",
        "        loss = loss_function(outputs, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        train_preds.extend(torch.sigmoid(outputs).cpu().detach().numpy())\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    train_losses.append(total_loss / len(train_loader))\n",
        "    train_aurocs.append(roc_auc_score(train_labels, train_preds))\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_pad, labels, adm_d, bd, x_len in val_loader:\n",
        "            x_pad, labels, adm_d, bd, x_len = x_pad.to(\"cuda\"), labels.to(\"cuda\"), adm_d.to(\"cuda\"), bd.to(\"cuda\"), x_len.to(\"cuda\")\n",
        "            outputs = model(x_pad, x_len, adm_d, bd)\n",
        "            loss = loss_function(outputs, labels.float())\n",
        "            val_loss += loss.item()\n",
        "            val_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_losses.append(val_loss / len(val_loader))\n",
        "    val_aurocs.append(roc_auc_score(val_labels, val_preds))\n",
        "\n",
        "    print(f'Epoch {epoch+1}: Train Loss {total_loss / len(train_loader):.4f}, Train AUROC {train_aurocs[-1]:.4f}, Val Loss {val_loss / len(val_loader):.4f}, Val AUROC {val_aurocs[-1]:.4f}')\n",
        "\n",
        "# Plotting training and validation metrics\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "ax1.plot(train_losses, label='Training Loss')\n",
        "ax1.plot(val_losses, label='Validation Loss')\n",
        "ax1.set_title('Training and Validation Loss per Epoch')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "ax2.plot(train_aurocs, label='Training AUROC')\n",
        "ax2.plot(val_aurocs, label='Validation AUROC')\n",
        "ax2.set_title('Training and Validation AUROC per Epoch')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('AUROC')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUjKGNX69er2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# This method returns the acuracy for each of the 5 time points from \n",
        "# the labels, in addition to the overall precision and recall\n",
        "def get_time_acc(model, val_loader):\n",
        "    model.eval()\n",
        "    acc = torch.zeros(5).to(\"cuda\")\n",
        "    prec = 0\n",
        "    rec = 0\n",
        "    with torch.no_grad():\n",
        "        for x_pad, labels, adm_d, bd, x_len in val_loader:\n",
        "            x_pad, labels, adm_d, bd, x_len = x_pad.to(\"cuda\"), labels.to(\"cuda\"), adm_d.to(\"cuda\"), bd.to(\"cuda\"), x_len.to(\"cuda\")\n",
        "            outputs = model(x_pad, x_len, adm_d, bd)\n",
        "            outputs = torch.sigmoid(outputs)\n",
        "            predictions = torch.round(outputs)\n",
        "            acc    += torch.sum(predictions == labels, axis=0) / labels.shape[0]\n",
        "            labels = labels.cpu().numpy()\n",
        "            predictions = predictions.cpu().numpy()\n",
        "            prec += precision_score(labels, predictions, average='macro', zero_division=0)\n",
        "            rec += recall_score(labels, predictions, average='macro', zero_division=0)\n",
        "    return acc / len(val_loader), prec / len(val_loader), rec / len(val_loader)\n",
        "\n",
        "\n",
        "get_time_acc(model, val_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
